
empiriques = grande population ?

certains tests on besoin de conditions (autres tests) pour être faits (normalité, indépendance, ...)
on distingue les tests paramétriques (modèle suit une loi normale) des tests non paramétriques

On peut voir graphiquement avec :code:`plot (default), ggplot (ggplot2), ...`

Statistiques pondérées
	Si on a des valeurs associés à une probabilités dans deux vecteurs, alors on peut soit
	les fusionner soit travailler dessus sans les désagréger avec :code:`wtd.mean(v,p)`,
	:code:`wtd.mean(v,p)`, ... du package :code:`questionr`.

5. Statistiques descriptives
==================================

Le but des statistiques descriptives est de décrire notre échantillon.

Améliorer nos graphiques
	On peut ajouter des droites comme la moyenne sur nos axes pour situer
	la répartition des données.

	On peut également tester la fonction de répartition (:code:`ecdf(rloi(...))` en R)
	en la superposant à un graphique précédemment obtenu (on rappelle le add=TRUE).

6. Statistique inférentielle
==============================

Test d’indépendance
------------------------

:code:`Motivation` : variables qualitatives indépendantes si p-value acceptable.

du Khi deux (:code:`chisq.test(tab,correct=FALSE)`)
	| :code:`Prérequis` : tab de 2 variables qualitatives, au moins 5 individus

	On peut regarder le :code:`$expected` pour vérifier ou encore les résidus
	:code:`$residuals` (valeur ij élevé = joue un rôle élevé dans la liaison des variables)
	calculés selon la formule :math:`(observed - expected) / sqrt(expected)`.

	Le correct corresponds à la correction de continuité (T=oui, F=non).

de Fisher (:code:`fisher.test(tab)`)
	| :code:`Prérequis` : tab de 2 variables qualitatives

	Très gourmand en ressources, préférez le célèbre test du Khi-Deux.

Test d’adéquation du Khi deux
--------------------------------

*Également appelé test de conformité*.

| :code:`Motivation` : tester si une distribution inconnue est de la forme d'une loi connue.
| :code:`chisq.test(observations , p = théorie)`

L'idée est d'observer la différence entre la théorie et nos valeurs.

On a généralement deux lois X (1,...,p) et Y (1, ..., q) alors on a une loi du Khi Deux
qui suit (p-1)(q-1) degrés de liberté (ou alors k-r-1 avec k groupes/classes, r paramètres estimés).

On note df le degré de liberté qu'il faut vérifier. Si R a échoué
a trouvé le bon degré, on devra faire le calcul manuellement.

.. code:: r

	> temp <- sum((observed-expected)^2/expected)
	> res <- 1-pchisq(temp, df=...vrai_df...)

Tests d’égalité de médiane
----------------------------------

avec le test des signes (:code:`SIGN.test(data, md = médiane, alternative = "two.sided", conf.level = 0.95)`)
	| :code:`Prérequis` : aucun

	La fonction est dans le package :code:`BSDA`.

(SignedRank) de Wilcoxon (:code:`wilcox.test(data, mu = mu, alternative = "two.sided", conf.level = 0.95)`)
	| :code:`Prérequis` : population symétrique

	Test plus puissant que le celui des signes (utilise le rang).

Mann–Whitney U (comparaison de 2 médianes)
	| :code:`Prérequis` : 2 échantillons n1 et n2 avec n1+n2>30, fonctions de répartition (ecdf) ne se croisent pas.
	| :code:`Info` : moyenne :math:`n1(n1+n2+1)/2` et variance :code:`n1n2(n1+n2+1)/12`
	| :code:`wilcox.test(data,alternative = "two.sided", conf.level = 0.95)`

	Aussi appelé Mann–Whitney–Wilcoxon (MWW), Wilcoxon rank-sum test, ou Wilcoxon–Mann–Whitney test.

Test sur les données appariés
-------------------------------

Test (de nullité) du coefficient de corrélation linéaire
	| :code:`Prérequis` : test de normalité ou plus de 30 individus, deux variables quantitatives
	| :code:`Résultat` : 0 = corrélation possible, ou valeur entre -1 et 1
	| :code:`Calcul` : :code:`cor.test()` (test de corrélation)

	Matrice des corrélations
		On peut utiliser :code:`cor.mtest(data)$p` du package :code:`corrplot`
		pour voir la matrice des corrélations, avec data une matrice ou un data.frame
		par exemple. On peut voir les corrélations deux à deux.

	On peut utiliser :code:`corrplot(cor(data), method="circle")` ou
	:code:`corrplot(cor(data), method="number")` du package :code:`corrplot`
	pour avoir un aperçu graphique.

ANOVA : analyse de la variance
------------------------------------

Anova a permet de comparer une ou plusieurs variables quantitatives
selon une ou plusieurs variables qualitatives. On va donc faire
des groupes de population selon un ou plusieurs critères.

Anova à un critère (n quantitative, 1 qualitative)
	| :code:`Prérequis` : test normalité, égalité des variances (peuvent être omis sous conditions)

	.. code:: R

		anova <- aov(data ~ qualif, data=data)
		summary(anova) # si Pr(>F) < 5% alors différence significative

	Le test compare les moyennes et si il est valide, alors le type (qualification)
	a une influence sur la variable quantitative (data, un dataframe de valeurs).

	Tests (des étendues) de Tukey/test DSH (:code:`TukeyHSD(anova)`)
		Ce test permet de voir si la différence des moyennes est significative ou non.
		On vérifie que "p adj" est supérieur à 5% sinon le test n'est pas valide.

Anova à deux critères (n quantitative, 2 qualitative)
	| :code:`Prérequis` : test normalité, égalité des variances
	| :code:`Exemple` : (Alcool,vitesse) sur risque d’accident

	.. code:: R

		anova <- aov(data ~ qualif1+qualif2+qualif1:qualif2, data=data)
		summary(anova) # si Pr(>F) < 5% alors différence significative

	On fait un test anova, sauf qu'on demande de faire data par qualification1,
	data par qualification2 puis data par qualification1 et qualification2
	(testez `qualif1:qualif2` pour voir le vecteur utilisé).
