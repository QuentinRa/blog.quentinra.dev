
empiriques = grande population ?

certains tests on besoin de conditions (autres tests) pour être faits (normalité, indépendance, ...)
on distingue les tests paramétriques (modèle suit une loi normale) des tests non paramétriques

On peut voir graphiquement avec :code:`plot (default), ggplot (ggplot2), ...`

Statistiques pondérées
	Si on a des valeurs associés à une probabilités dans deux vecteurs, alors on peut soit
	les fusionner soit travailler dessus sans les désagréger avec :code:`wtd.mean(v,p)`,
	:code:`wtd.mean(v,p)`, ... du package :code:`questionr`.

5. Statistiques descriptives
==================================

Le but des statistiques descriptives est de décrire notre échantillon.

Améliorer nos graphiques
	On peut ajouter des droites comme la moyenne sur nos axes pour situer
	la répartition des données.

	On peut également tester la fonction de répartition (:code:`ecdf(rloi(...))` en R)
	en la superposant à un graphique précédemment obtenu (on rappelle le add=TRUE).

6. Statistique inférentielle
==============================

QQ plot/Diagramme Quantile-Quantile
	Si les observations et la distribution sont la même, alors les points
	tourneront autour de la droite. Cela peut être un moyen utile de vérifier un test.

	On utilisera les fonctions comme :code:`qqplot, qqline, qq, ...`. :code:`datax=TRUE` est utile
	pour mettre en fonction de l'axe x.

-----> DIAGRAMME QUANTILE-QUANTILE

Une autre manière de juger qualitativement de l'ajustement de données expérimentales avec une loi
théorique (quelle qu'elle soit!!!) est l'utilisation d'un "diagramme quantile-quantile".

L'idée est assez simple, il s'agit de comparer les données expérimentales, aux données théoriques
supposées suivre une loi donnée.

Et bien évidemment on peut comparer les quantiles observés à toute loi théorique supposée. Plus les
points seront alignés sur la droite, meilleur sera l'ajustement! C'est très visuel, très simple et beaucoup
utilisé par les non spécialistes en statistiques dans les entreprises.

Test paramétriques et non paramétriques (distribution free)
	Un test paramétrique demande a ce que la distribution suive une loi normale
	ce qui est le cas pour de nombreux tests (anova, Student T, ...). Les
	autres, dits non paramétriques, sont moins puissants mais ne demande pas ce prérequis.

Test d’indépendance
------------------------

:code:`Motivation` : variables qualitatives indépendantes si p-value acceptable.

du Khi deux (:code:`chisq.test(tab,correct=FALSE)`)
	| :code:`Prérequis` : tab de 2 variables qualitatives, au moins 5 individus

	On peut regarder le :code:`$expected` pour vérifier ou encore les résidus
	:code:`$residuals` (valeur ij élevé = joue un rôle élevé dans la liaison des variables)
	calculés selon la formule :math:`(observed - expected) / sqrt(expected)`.

	Le correct corresponds à la correction de continuité (T=oui, F=non).

de Fisher (:code:`fisher.test(tab)`)
	| :code:`Prérequis` : tab de 2 variables qualitatives

	Très gourmand en ressources, préférez le célèbre test du Khi-Deux.

Test d’adéquation du Khi deux
--------------------------------

*Également appelé test de conformité*.

| :code:`Motivation` : tester si une distribution inconnue est de la forme d'une loi connue.
| :code:`chisq.test(observations , p = théorie)`

L'idée est d'observer la différence entre la théorie et nos valeurs.

On a généralement deux lois X (1,...,p) et Y (1, ..., q) alors on a une loi du Khi Deux
qui suit (p-1)(q-1) degrés de liberté (ou alors k-r-1 avec k groupes/classes, r paramètres estimés).

On note df le degré de liberté qu'il faut vérifier. Si R a échoué
a trouvé le bon degré, on devra faire le calcul manuellement.

.. code:: r

	> temp <- sum((observed-expected)^2/expected)
	> res <- 1-pchisq(temp, df=...vrai_df...)

Test de normalité
------------------

| :code:`Motivation` : tester si une distribution suit une loi normale/gaussienne.

| de **Shapiro-Wilk** : :code:`shapiro.test()`
| de **Anderson-Darling** (package nortest)  : :code:`ad.test()`
| de **Cramer-von Mises** (package nortest) : :code:`cvm.test()`

Droite de Henry
	Il s'agit d'un QQ-Plot mais pour une loi normale. On utilise
	la fonction :code:`qqnorm` pour tracer les points et :code:`qqline`
	pour tracer la droite.

Test de comparaison/sur les proportions
----------------------------------------

| :code:`Motivation` : trouver la proportion d'individus suivant un certain critère

Cas 1 proportion (:code:`prop.test(x,n,p=proba,correct=FALSE)` (ou binom.test))
	On a reçu x succès sur n, p=proba et on veut vérifier si c'est vrai

	Le résultat indique l'intervalle dans lequel peut être p et sa valeur estimée,
	en plus de p-value.

Cas 2 proportions (:code:`prop.test(x=c(x,y), n=c(N1,N2),correct=FALSE)`)
	On a x succès sur N1 et y sur N2.

Tests d'égalités de variances
----------------------------------

de Fisher (2 variances, :code:`var.test(...)`)
	:code:`Prérequis` : test de normalité ok, populations indépendantes

	On peut donner deux dataset (x,y) ou un dataset (data) et un dataset divisé en 2 groupes (formula).

	En gros vous pouvez soit tester la variance en général de deux jeux de données ou alors
	vous pouvez filtrer pour prendre une seule variable, divisée par groupe et tester l'égalité de
	la variance des sous-groupes.

de Bartlett (:code:`bartlett.test(v_quantitatif, v_qualitatif)`)
	:code:`Prérequis` : test de normalité ok, 4 individus minimum par échantillon et pas trop d'échantillons par rapport à leur taille

	On va donner un vecteur de valeurs quantitatives et un vecteur qualitatif (factor) permettant
	de faire des groupes (échantillons) de valeurs du premier vecteur. On va ensuite
	comparer l'égalité de la variance de chaque groupe. Il est moins puissant que Fisher.

Tests d’égalité de moyennes
----------------------------------

On suppose une population de plus de 30 individus ou alors que vous avez fait le test
de normalité.

de Student T à moyenne fixée (:code:`t.test(x=data, alternative="two.sided", mu=valeur)`)
	| :code:`Prérequis` : test de normalité ou plus de 30 individus

	| (2) :code:`t.test(x=data1, y=data2, alternative="two.sided", var.equal=TRUE)`

	Elle consiste a tester si pour un échantillon la moyenne vaut bien mu.

de Student T a deux moyennes (:code:`t.test(x=data1, y=data2, alternative="two.sided", var.equal=TRUE)`)
	| :code:`Prérequis` : test de normalité ou plus de 30 individus, test de variance égales

	On test si la moyenne de deux échantillons est la même.

Tests d’égalité de médiane
----------------------------------

avec le test des signes (:code:`SIGN.test(data, md = médiane, alternative = "two.sided", conf.level = 0.95)`)
	| :code:`Prérequis` : aucun

	La fonction est dans le package :code:`BSDA`.

(SignedRank) de Wilcoxon (:code:`wilcox.test(data, mu = mu, alternative = "two.sided", conf.level = 0.95)`)
	| :code:`Prérequis` : population symétrique

	Test plus puissant que le celui des signes (utilise le rang).

Mann–Whitney U (comparaison de 2 médianes)
	| :code:`Prérequis` : 2 échantillons n1 et n2 avec n1+n2>30, fonctions de répartition (ecdf) ne se croisent pas.
	| :code:`Info` : moyenne :math:`n1(n1+n2+1)/2` et variance :code:`n1n2(n1+n2+1)/12`
	| :code:`wilcox.test(data,alternative = "two.sided", conf.level = 0.95)`

	Aussi appelé Mann–Whitney–Wilcoxon (MWW), Wilcoxon rank-sum test, ou Wilcoxon–Mann–Whitney test.

Test sur les données appariés
-------------------------------

Test (de nullité) du coefficient de corrélation linéaire
	| :code:`Prérequis` : test de normalité ou plus de 30 individus, deux variables quantitatives
	| :code:`Résultat` : 0 = corrélation possible, ou valeur entre -1 et 1
	| :code:`Calcul` : :code:`cor.test()` (test de corrélation)

	Matrice des corrélations
		On peut utiliser :code:`cor.mtest(data)$p` du package :code:`corrplot`
		pour voir la matrice des corrélations, avec data une matrice ou un data.frame
		par exemple. On peut voir les corrélations deux à deux.

	On peut utiliser :code:`corrplot(cor(data), method="circle")` ou
	:code:`corrplot(cor(data), method="number")` du package :code:`corrplot`
	pour avoir un aperçu graphique.

ANOVA : analyse de la variance
------------------------------------

Anova a permet de comparer une ou plusieurs variables quantitatives
selon une ou plusieurs variables qualitatives. On va donc faire
des groupes de population selon un ou plusieurs critères.

Anova à un critère (n quantitative, 1 qualitative)
	| :code:`Prérequis` : test normalité, égalité des variances (peuvent être omis sous conditions)

	.. code:: R

		anova <- aov(data ~ qualif, data=data)
		summary(anova) # si Pr(>F) < 5% alors différence significative

	Le test compare les moyennes et si il est valide, alors le type (qualification)
	a une influence sur la variable quantitative (data, un dataframe de valeurs).

	Tests (des étendues) de Tukey/test DSH (:code:`TukeyHSD(anova)`)
		Ce test permet de voir si la différence des moyennes est significative ou non.
		On vérifie que "p adj" est supérieur à 5% sinon le test n'est pas valide.

Anova à deux critères (n quantitative, 2 qualitative)
	| :code:`Prérequis` : test normalité, égalité des variances
	| :code:`Exemple` : (Alcool,vitesse) sur risque d’accident

	.. code:: R

		anova <- aov(data ~ qualif1+qualif2+qualif1:qualif2, data=data)
		summary(anova) # si Pr(>F) < 5% alors différence significative

	On fait un test anova, sauf qu'on demande de faire data par qualification1,
	data par qualification2 puis data par qualification1 et qualification2
	(testez `qualif1:qualif2` pour voir le vecteur utilisé).
