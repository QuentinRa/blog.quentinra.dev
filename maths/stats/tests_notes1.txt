"independant one-sample t-test" (en anglais) ou "test-T à 1 échantillon":
"test-T bilatéral sur la différence de deux moyennes".

"test-T de deux moyennes d'échantillons appariés (ou échantillons dépendants)".

Avant d'aller plus en détails, rappelons qu'il faut être extrêmement prudent quant à la manière d'obtenir
les deux échantillons. Il faut que l'expérience soit non biaisée, cela signifie pour rappel, que le protocole
de tirage ne doit en aucun cas avantager l'une au l'autre des caractéristiques de la population (si vous
étudiez l'équilibre homme/femme dans une population en attirant dans le sondage des personnes grâce à
un cadeau sous la forme de bijoux vous aurez alors un échantillon biaisé... car vous aurez probablement
naturellement plus de femmes que d'hommes...).

Ceci étant fait, pour construire le test et de par l'asymétrie de la distribution, nous allons calculer la
probabilité cumulée que k soit plus petit que le x obtenu par l'expérience et la sommer à la probabilité
cumulée pour que k soit plus grand que le y obtenu par l'expérience (ce qui correspond à la probabilité
cumulée des queues respectivement gauche et droite de la distribution).
et cette dernière relation est appelée "test binomial exact (bilatéral)".

Si la probabilité P obtenue pour la somme est au-dessus d'une certaine probabilité cumulée fixée à
l'avance, nous dirons alors que la différence avec un échantillon tiré au hasard dans une population
parfaitement équilibrée n'est pas significative (en bilatéral...) et respectivement si elle est en-dessous, la
différence sera donc significative et nous rejetterons l'équilibre supposé.

---- TEST DE L'ÉGALITÉ DE DEUX PROPORTIONS

Toujours dans le même contexte que l'approximation précédente de la loi Binomiale par une loi
Normale, l'industrie (en particulier la biostatistique) est friande de comparer deux proportions de deux
populations différentes afin de savoir si elles sont statistiquement égales ou non (autrement dit:
significativement différentes ou pas).

test Z de l'égalité de deux proportions

48/50 et 26/30 ~~~ 95% ?

---- TEST DES SIGNES

Nous mesurons quelque chose sur un échantillon puis, plus tard, nous mesurons la même chose sur ce
même échantillon mais avec une autre méthode (donc il s'agit donc d'échantillons appariés!). Les deux
classements ordonnées des mesures sont comparés et chaque observation est affectée d'un signe ("+"
en cas d'élévation dans le classement, "–" en cas de descente). Celles qui restent au même niveau sont
éliminées.
Selon l'hypothèse à tester, il y a autant de "+" que de "–", c'est-à-dire que la médiane de la distribution
n'a pas bougé (cette affirmation peut ne pas paraître évidente à la première lecture il faut donc bien
prendure du temps parfois pour réfléchir là-dessus).

D1. "L'intervalle de tolérance" (ou "intervalle de fluctuation") est un intervalle contenant un certain
pourcentage (souvent 68.26, 95.44 ou 99.73%) des individus d'une population de mesures.
D2. "L'intervalle de confiance" pour un échantillon de moyenne contient l'intervalle de valeur à un
niveau de confiance donné (souvent 90, 95 ou 99%) de l'espérance (moyenne vraie) de la
population.
D3. "L'intervalle de prédiction" permet de déterminer un intervalle d'un valeur individuelle basée sur la
connaissance de la moyenne échantillonnale et de l'écart-type de la population.

========= TESTS D'HYPOTHÈSE ET D'ADÉQUATION

Définition: Lorsque nous cherchons à savoir si nous pouvons faire confiance à la valeur d'une
statistique (moyenne, médiane, variance, coefficient de corrélation, etc.) avec une certaine certitude,
nous parlons de "test d'hypothèse" et plus particulièrement de "test de conformité" (nous parlons de
"test d'adéquation" quand il s'agit de vérifier que des mesures suivent bien une loi donnée et non juste
une statistique).

Les tests d'hypothèses sont destinés à vérifier si un échantillon peut être considéré comme extrait d'une
population donnée ou représentatif de cette population, vis-à-vis d'un paramètre comme la moyenne, la
variance ou la fréquence observée. Ceci implique que la loi théorique du paramètre soit connue au
niveau de la population. Les tests d'hypothèses ne sont pas faits pour démontrer l'hypothèse nulle
(exprimant généralement une égalité ou une homogénéité entre différentes populations), mais pour
éventuellement la rejeter (dispons pour être exact que le rejet est plus robuste).

Nous parlons du "test-Z de la moyenne à deux échantillons" et il est beaucoup utilisé dans l'industrie
pour vérifier l'égalité de la moyenne de deux populations de mesures.

Et si l'écart-type théorique n'est pas connu, nous utiliserons le "test-T" de Student (pas mal utilisé en
pharmaco-économie)

Dans la même idée pour l'écart-type, nous utiliserons le "test du Khi-deux"

lorsque nous voulons tester l'égalité de la variance de deux populations nous utilisons le "test-F"
de Fisher

Dans la pratique il faut avoir conscience que le but d'un test est très très souvent de montrer que l'effet
est significatif. Il est alors d'usage de dire que le test réussit si l'hypothèse nulle est rejetée au profit de
l'hypothèse alternative. Lorsque le praticien sait que l'effet est significatif et pourtant que son test

Signalons aussi que les tests d'hypothèses sur l'écart-type (variance), la moyenne ou la corrélation sont
appelés des "tests paramétriques" à l'inverse des tests non paramétriques que nous verrons beaucoup
plus loin.

Enfin, de nombreux logiciels calculent ce que nous appelons la "p-value" qui est le risque calculé
(probabilité) alpha (ou t) qu'aurait pu fixer le statisticien pour être à la limite entre l'acceptation de l'hypothèse
nulle et son rejet (rappelons qu'un test qui réussit ne prouve rien). La p-value est donc une valeur
fondamentale dans le domaine car elle permet de chiffrer la vraisemblance de l'hypothèse nulle H0
(acception ou rejet).
Pour un test d'hypothèse, par exemple, le 5% de risque est celui de rejeter l'hypothèse nulle H0
alors même qu'elle est vraie. Si le risque imposé/choisi est 5% et que la p-value calculée est inférieure
(dans la majorité des tests mais il faut être prudent car ce n'est pas une généralité!!!), le test échoue
(rejet de l'hypothèse) en faveur d'une hypothèse alternative notée ou parfois .

Remarque: Il existe un type d'ANOVA prévu pour le cas où les variables ne sont pas indépendantes
(on parle alors de "covariable"). Il s'agit de l'ANCOVA qui signifie "Analyse de la COvariance et de
la VAriance" qui utilise un mix entre la régression linéaire (cf. chapitre de Méthodes Numériques) et
l'ANOVA. Le but de l'ANCOVA est de supprimer statistiquement l'effet indirect de la covariable.

----- ANALYSE DE LA VARIANCE (À UN FACTEUR)

L'objectif de l'analyse de la variance (contrairement à ce que son nom pourrait laisser penser) est une
technique statistique permettant de comparer les moyennes de deux populations ou plus (très utilisé
dans le pharma ou dans les labos de R&D ou de bancs d'essais). Cette méthode, néanmoins, doit son
nom au fait qu'elle utilise des mesures de variance afin de déterminer le caractère significatif, ou non,
des différences de moyennes mesurées sur les populations.
Plus précisément, la vraie signification est de savoir si le fait que des moyennes d'échantillons sont
(légèrement) différentes peut être attribué au hasard de l'échantillonnage ou provient du fait qu'un
facteur de variabilité engendre réellement des échantillons significativement différents (si nous avons
les valeurs de toute la population, nous n'avons rien à faire!).

Pour l'analyse de la variance appelée "ANOVA à un facteur" (ANalysis Of VAriance) ou "ANAVAR à
un facteur" (ANAlyse de la VARiance), ou encore "ANOVA à une voie" ou plus rigoureusement
"ANOVA à un facteur fixe avec répétitions" ou encore "ANOVA à une variable catégorielle fixe avec
répétition", nous allons d'abord rappeler, comme nous l'avons démontré, que la loi de Fisher-Snedecor
est donnée par le rapport de deux variables aléatoires indépendantes qui suivent une loi du Khi-deux et
divisée par leur degré de liberté tel que:

Pour valider l'utilité d'un facteur, il met au point un test permettant
d'assurer que des échantillons différents sont de natures différentes. Ce test est basé sur l'analyse de la
variance (des échantillons), et nommé ANOVA (analyse normalisée de la variance).
Prenons k échantillons de n valeurs aléatoires chacun. Chacune des valeurs étant considérée comme
une observation ou une mesure de quelque chose ou sur la base de quelque chose (un lieu différent, ou
un objet différent... bref: un seul et unique facteur de variabilité entre les échantillons!). Nous aurons
donc un nombre total de N d'observations (mesures) donné par:

N = kn
si chacun des échantillons a un nombre identique de valeurs n (taille de l'échantillon) tel que
nous parlons alors de "plan équilibré" à k niveaux (ou k modalités)

En termes de test, nous voulons tester si les moyennes des k échantillons de taille n sont égales sous
l'hypothèse que leurs variances sont égales.

Autrement dit: les échantillons sont représentatifs d'une même population (d'une même loi statistique).
C'est-à-dire que les variations constatées entre les valeurs des différents échantillons sont dues
essentiellement au hasard. Pour cela nous étudions la variabilité des résultats dans les échantillons et
entre les échantillons.

La "variance totale" comme étant intuitivement la variance estimée sans biais en considérant
l'ensemble des N observations comme un seul échantillon:
où le terme au numérateur est appelé "somme des carrés des écarts totaux".

2. La "variance entre échantillons" (c'est-à-dire entre les moyennes des échantillons) est aussi
intuitivement l'estimateur de la variance des moyennes des échantillons:
où le terme au numérateur est appelé "somme des carrés des écarts entre échantillons".

3. La "variance résiduelle" est l'effet des facteurs dits non contrôlés. C'est par définition la moyenne des
variances des échantillons (en quelque sorte: l'erreur standard):
où le terme au numérateur est appelé "somme des carrés des écarts des résidus" ou encore plus souvent
"erreur résiduelle".

R1. Le terme est souvent indiqué dans l'industrie par l'abréviation SST signifiant en anglais
"Sum of Squares Total" ou plus rarement TSS pour "Total Sum of Squares".
R2. Le terme est souvent indiqué dans l'industrie par l'abréviation SSB signifiant en anglais
"Sum of Squares Between (samples)" ou plus rarement SSk pour "Sum of Squares Between
treatments".
R3. Le terme est souvent indiqué dans l'industrie par l'abréviation SSW signifiant en anglais
"Sum of Squares Within (samples)" ou plus rarement SSE pour "Sum of Squares due to Errors".

Cette dernière relation est appelée "independent 2-sample T-test", ou "test-T
homoscédastique" ou encore "test-T d'égalité des espérances de 2 observations avec variances
égales" ou encore plus simplement mais un peu abusivement "test-T à 2 échantillons", avec taille
des échantillons différentes et variances égales. Souvent dans la littérature, les deux moyennes
théoriques sont égales lors de la comparaison.

Il faut cependant bien se rappeler que pour utiliser l'ANOVA, on doit donc supposer que les
échantillons sont issus d'une même population (données appariées) et suivent une loi normale. Il est
donc nécessaire de vérifier la normalité des distributions et l'homoscédasticité (test de Levene par
exemple). Dans le cas contraire, il faut utiliser des variantes non paramétriques de l'analyse de variance
(ANOVA de Kruskal-Wallis ou ANOVA de Friedman).

------------ test khi deux

Pour évaluer ces écarts et pouvoir prendre une décision, il faut:
1. Définir la mesure de la distance entre distribution empirique et distribution théorique résultant de la
loi retenue.
2. Déterminer la loi de probabilité suivie par cette variable aléatoire donnant la distance.
3. Énoncer une règle de décision permettant de dire, d'après la distribution observée, si la loi retenue est
acceptable ou non.

De ce que j'ai compris
- on a des fréquences=observations~critère pour des critères
- on a une somme des observations
- en théorie, tous les fréquences sont égales donc on a
- fréquence_th = observations/#critères
Il s'agit donc d'examiner
la différence entre les fréquences observées et les fréquences théoriques (supposées suivre une loi
uniforme) en suivant la relation du Khi-deux. En d'autres termes, nous allons faire un test d'ajustement
entre une fonction de distribution empirique (observée) et la fonction de distribution uniforme. Nous
avons alors
(observation_i - observation_th_i)^2
/
observation_th_i
pour tout critère
la somme est ... = chi^2
% qui indique le % que ce soit probable.

================== STATISTIQUES DE RANGS

Les statistiques de rangs, appelées aussi "statistiques d'ordre", sont définies comme l'ensemble des
techniques de calculs statistiques ou d'inférence statistiques qui ont pour objectif principal de se
débarrasser de la connaissance d'une distribution paramétrée et en utilisant pour cela uniquement les
rangs (ordonnés) des caractéristiques mesurées. Il s'agit d'un outil très puissant et très utilisé dans la
pratique pour faire de la statistique non-paramétrée!

---------------

(1) Test-T de Student
Type:
Test d'hypothèse paramétrique de type intervalle de confiance souvent utilisé en bilatéral
Concerne:
La moyenne lorsque l'écart-type théorique est inconnu
Contrainte(s):
Distribution Normale des données.
(2) Test-p de l'intervalle de confiance de proportions
Type:
Test d'hypothèse paramétrique de type intervalle de confiance souvent utilisé en bilatéral
Concerne:
La proportion de bons ou mauvais éléments dans une population
Contrainte(s):
Distribution Binomiale (et asymptotiquement) Normale des données (n*p>=5).

(3) Test-p de l'égalité de deux proportions
Type:
Test d'hypothèse paramétrique de type intervalle de confiance souvent utilisé en unilatéral
Concerne:
L'égalité de deux proportions
Contrainte(s):
Distribution Binomiale (et asymptotiquement) Normale des données (n*p>=5).

(4) Test binomial exact (égalité de deux proportions)
Type:
Test d'hypothèse paramétrique de type intervalle de confiance souvent utilisé en bilatéral
Concerne:
L'égalité de deux proportions.
Contrainte(s):
Distribution Binomiale (petit échantillon d'un grande population)
(5) Test des signes (de la médiane) de deux échantillons appariés
Type:
Test d'hypothèse non-paramétrique de type intervalle de confiance souvent utilisé en bilatéral
Concerne:
L'égalité des signes (implicitement des différences) de données appariées
Contrainte(s):
Distribution Binomiale (petit échantillon d'un grande population) mais valeurs sous-jacentes continues.
(6) Test-T de Student de deux moyennes d'échantillons appariés
Type:
Test d'hypothèse paramétrique de type intervalle de confiance souvent utilisé unilatéral.
Concerne:
La différence de deux moyennes de deux échantillons identiques
Contrainte(s):
Distribution Normale des données
(7) Test-Z
Type:
Test d'hypothèse paramétrique de type intervalle de confiance plus utilisé en bilatéral qu'en unilatéral.
Concerne:
La moyenne lorsque l'écart-type théorique est connu
Contrainte(s):
Distribution Normale des données

8) Test-Z de la moyenne à deux échantillons
Type:
Test d'hypothèse paramétrique de type intervalle de confiance souvent utilisé en bilatéral
Concerne:
La différence de deux moyennes lorsque les écarts-types théoriques sont connus
Contrainte(s):
Distribution Normale des données
(9) Test du Khi-deux
Type:
Test d'hypothèse paramétrique de type intervalle de confiance souvent utilisé en bilatéral
Concerne:
La variance théorique
Contrainte(s):
Distribution Normale des données
(10) Test-F de Fisher
Type:
Test d'hypothèse paramétrique de type intervalle de confiance souvent utilisé en bilatéral
Concerne:
La comparaison de deux variances théoriques
Contrainte(s):
Distribution Normale des données
(11) Test-T homoscédastique
Type:
Test d'hypothèse paramétrique de type intervalle de confiance souvent utilisé en unilatéral
Concerne:
L'égalité de deux moyennes
Contrainte(s):
Distribution Normale des données et égalité des variances expérimentales

(12) Test-T hétéroscédastique
Type:
Test d'hypothèse paramétrique de type intervalle de confiance souvent utilisé en unilatéral
Concerne:
L'égalité de deux moyennes
Contrainte(s):
Distribution Normale des données et non-égalité des variances expérimentales (cas généralisé du Test-T
homoscédastique)
(13) Test de l'ANOVA à un facteur contrôlé
Type:
Test d'hypothèse paramétrique de type intervalle de confiance utilisé uniquement en unilatéral
Concerne:
L'égalité des moyennes des échantillons (supposés implicitement appariés)
Contrainte(s):
Distribution Normale des données avec variances théoriques identiques et variances expérimentales connues et
indépendance des échantillons. Les résidus doivent in extenso aussi être normalement distributés
(14) Test de l'ANOVA à deux facteurs contrôles avec ou sans répétition
Type:
Test d'hypothèse paramétrique de type intervalle de confiance utilisé uniquement en unilatéral
Concerne:
L'égalité des moyennes des échantillons fonction d'un paramètre variable contrôlable (ajustable).
Contrainte(s):
Distribution Normale des données avec variances théoriques identiques et variances expérimentales connues et
indépendance des échantillons. Les résidus doivent in extenso aussi être normalement distributés.
(15) Test d'ajustement (dit aussi "test d'adéquation de Pearson") du Khi-deux
Type:
Test d'ajustement paramétrique utilisé uniquement en unilatéral
Concerne:
Adéquation de valeurs expérimentales à une loi théorique
Contrainte(s):
Avoir suffisamment de classes d'intervalles et de données
Remarque: Appelé "Test de normalité" si comparé à une loi Normale.

(16) Test d'indépendance du Khi-deux
Type:
Test d'ajustement (étudié dans le chapitre de Méthodes Numériques) paramétrique utilisé uniquement en
unilatéral
Concerne:
Vérifier la dépendance ou l'indépendance (différence) de données provenant d'une table de contingence. Vérifie
donc si les moyennes sont différentes ou pas entre groupes en se basant sur la contingence
Contrainte(s):
Avoir suffisamment de classes d'intervalles et de données
(17) Test de la médiane
Type:
Test d'hypothèse non paramétrique étudié dans le chapitre de Méthodes Numériques de type intervalle de
confiance toujours utilisé en bilatéral
Concerne:
La médiane
Contrainte(s):
Un nombre d'échantillons suffisant pour faire un bootstrap.

(19) Test de Poisson à un et deux échantillons
Type:
Tests d'hypothèses paramétrique tantôt en unilatéral ou bilatéral basé sur les événements rares (dixit la moyenne
de la loi de Poisson)
Concerne:
Déterminer un intervalle de confiance pour l'occurrence d'événements rares sur une période donnée afin
d'identifier une anomalie ou une différence significative par rapport à des objectifs ou des nromes.
Contrainte(s):
Les événements suivent une loi de Poisson mais sont approximés dans le cas à deux échantillons par une loi
Normale...

(24) Test exact de Fisher
Type:
Test d'ajustement (étudié dans le chapitre de Méthodes Numériques) paramétrique utilisé principalement en
bilatérial
Concerne:
Vérifier si la configuration observée dans un tableau de contingence est une situation extrême par rapport aux
situations possibles.
Contrainte(s):
Aucune en particulière

Les tests non paramétriques (comme les deux tests du Khi-deux déjà vus) ne font eux aucune
hypothèse sur la distribution sous-jacente des données. L'étape préalable qui consistait uniquement à
estimer les paramètres des distributions avant de procéder au test d'hypothèse proprement dit n'est plus
nécessaire.
Lorsque les données sont quantitatives, les tests non paramétriques transforment les valeurs en rangs.
L'appellation "tests de rangs" est alors souvent rencontrée. Lorsque les données sont qualitatives, seuls
les tests non paramétriques sont utilisables.

========== RANG

on ordonne toutes les valeurs de X et Y
la première est R1 (rang 1), si deux valeurs == alors même i-ème de rang

On fait la somme des i pour chaque X/Y : Valeurs que nous appelons "statistique de Wilcoxon".

l'espérance de la loi discrète uniforme
(n+1)/2 = mu
n^2-1/12 = V(x)

---------- TEST DE LA SOMME DES RANGS DE MANN-WITHNEY

Le "test de la somme des rangs de Mann-Withney" est au fait un test d'ajustement non-paramétrique
très simple qui se déduit du test de la somme des rangs de Wilcoxon. Par ailleurs il en est inspiré à un
tel point que nous l'appelons parfois dans l'industrie le "test de Wilcoxon-Mann-Withney" ou "test
d'ajustement de Wilcoxon-Mann-Withney" ou encore"test MWW" (sans spécifier à chaque fois qu'il
repose sur la somme des rangs).

Le but de ce test, identiquement au test de la somme des rangs de Wilcoxon, est de trouver un moyen
de vérifier que deux échantillons indépendants non nécessairement de même taille sont issus d'une
même loi ou non (in extenso sont issus d'une même population ou non) mais avec une approche
différente!

---------- TEST DE LA SOMME DES RANGS SIGNÉS DE WILCOXON À 1 ÉCHANTILLON

Le but du test de la "somme des rangs signés de Wilcoxon", appelé aussi parfois "test de la médiane de
Wilcoxon", est d'utiliser une technique non paramétrique pour vérifier la symétrie ou non d'une
distribution et donc in extenso faire une hypothèse sur la valeur de la médiane. L'idée est à la fois
simple et subtile.

Le principe et que si nous comparons les différences des individus d'un échantillon par rapport à la
médiane, nous savons que si nous avons (par exemple) un nombre impair d'individus tous différents
(non égaux), alors nous aurons 50% des données au-dessus et en-dessous de la médiane. Ensuite, pour
contrôler que la distribution des valeurs des individus vérifie une certaine symétrie, l'idée (simple mais
astucieuse) consiste ensuite à:
1. Calculer les différences en valeur absolue par rapport à la médiane
2. Ranger ces différences absolues par ordre croissant et leur assigner leur rang respectif
3. Calculer la somme des rangs des différences qui à la base sont négatives
4. Calculer la somme des rangs des différences qui à la base sont positives
et si l'échantillon a une distribution symétrique (donc la médiane est confondue alors avec la moyenne),
il devrait y avoir une somme des rangs négatifs qui n'est pas significativement différente de la
sommes des rangs positifs .

------- TEST DE LA SOMME DES RANGS SIGNÉS DE WILCOXON POUR 2 ÉCHANTILLONS APPARIÉS
Le "test de la somme des rangs signés de Wilcoxon pour 2 échantillons appariés" est basé à 100% sur le
principe du test à 1 échantillon. La seule différence est que l'hypothèse nulle ou alternative est basée
sur la différence de la médiane des données prises deux à deux de chacun des échantillons. Dans la
majorité des cas, l'hypothèse nulle est que la médiane des différences est nulle contre l'hypothèse
alternative qu'elle est significativement différente de zéro.

-------- TEST DE KRUSKAL-WALLIS

Le test de Kruskal-Wallis un test non paramétrique souvent assimilé (un peu rapidement...) à une
ANOVA non paramétrique à une voie pour comparer si deux populations ou plus ont même médiane
(hypothèse nulle) à la différence qu'il ne nécessite donc pas les hypothèses nécessaires au
fonctionnement de l'ANOVA. Quand plusieurs populations comparées passent à travers ce test, ce
dernier ne dit pas quelle population est significativement différente mais uniquement qu'il y en a au
moins une qui l'est. En réalité, comme nous allons le démontrer, le test de Kruskal-Wallis n'est qu'une
extension du test U de Mann-Whitney vu plus haut pour un nombre de populations supérieur ou égal à
trois.