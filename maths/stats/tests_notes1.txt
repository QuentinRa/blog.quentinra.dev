
----- ANALYSE DE LA VARIANCE (À UN FACTEUR)

Cette dernière relation est appelée "independent 2-sample T-test", ou "test-T
homoscédastique" ou encore "test-T d'égalité des espérances de 2 observations avec variances
égales" ou encore plus simplement mais un peu abusivement "test-T à 2 échantillons", avec taille
des échantillons différentes et variances égales. Souvent dans la littérature, les deux moyennes
théoriques sont égales lors de la comparaison.

Il faut cependant bien se rappeler que pour utiliser l'ANOVA, on doit donc supposer que les
échantillons sont issus d'une même population (données appariées) et suivent une loi normale. Il est
donc nécessaire de vérifier la normalité des distributions et l'homoscédasticité (test de Levene par
exemple). Dans le cas contraire, il faut utiliser des variantes non paramétriques de l'analyse de variance
(ANOVA de Kruskal-Wallis ou ANOVA de Friedman).

------------ test khi deux

Pour évaluer ces écarts et pouvoir prendre une décision, il faut:
1. Définir la mesure de la distance entre distribution empirique et distribution théorique résultant de la
loi retenue.
2. Déterminer la loi de probabilité suivie par cette variable aléatoire donnant la distance.
3. Énoncer une règle de décision permettant de dire, d'après la distribution observée, si la loi retenue est
acceptable ou non.

De ce que j'ai compris
- on a des fréquences=observations~critère pour des critères
- on a une somme des observations
- en théorie, tous les fréquences sont égales donc on a
- fréquence_th = observations/#critères
Il s'agit donc d'examiner
la différence entre les fréquences observées et les fréquences théoriques (supposées suivre une loi
uniforme) en suivant la relation du Khi-deux. En d'autres termes, nous allons faire un test d'ajustement
entre une fonction de distribution empirique (observée) et la fonction de distribution uniforme. Nous
avons alors
(observation_i - observation_th_i)^2
/
observation_th_i
pour tout critère
la somme est ... = chi^2
% qui indique le % que ce soit probable.

================== STATISTIQUES DE RANGS

Les statistiques de rangs, appelées aussi "statistiques d'ordre", sont définies comme l'ensemble des
techniques de calculs statistiques ou d'inférence statistiques qui ont pour objectif principal de se
débarrasser de la connaissance d'une distribution paramétrée et en utilisant pour cela uniquement les
rangs (ordonnés) des caractéristiques mesurées. Il s'agit d'un outil très puissant et très utilisé dans la
pratique pour faire de la statistique non-paramétrée!

---------------

(1) Test-T de Student
Type:
Test d'hypothèse paramétrique de type intervalle de confiance souvent utilisé en bilatéral
Concerne:
La moyenne lorsque l'écart-type théorique est inconnu
Contrainte(s):
Distribution Normale des données.
(2) Test-p de l'intervalle de confiance de proportions
Type:
Test d'hypothèse paramétrique de type intervalle de confiance souvent utilisé en bilatéral
Concerne:
La proportion de bons ou mauvais éléments dans une population
Contrainte(s):
Distribution Binomiale (et asymptotiquement) Normale des données (n*p>=5).

(3) Test-p de l'égalité de deux proportions
Type:
Test d'hypothèse paramétrique de type intervalle de confiance souvent utilisé en unilatéral
Concerne:
L'égalité de deux proportions
Contrainte(s):
Distribution Binomiale (et asymptotiquement) Normale des données (n*p>=5).

(4) Test binomial exact (égalité de deux proportions)
Type:
Test d'hypothèse paramétrique de type intervalle de confiance souvent utilisé en bilatéral
Concerne:
L'égalité de deux proportions.
Contrainte(s):
Distribution Binomiale (petit échantillon d'un grande population)
(5) Test des signes (de la médiane) de deux échantillons appariés
Type:
Test d'hypothèse non-paramétrique de type intervalle de confiance souvent utilisé en bilatéral
Concerne:
L'égalité des signes (implicitement des différences) de données appariées
Contrainte(s):
Distribution Binomiale (petit échantillon d'un grande population) mais valeurs sous-jacentes continues.
(6) Test-T de Student de deux moyennes d'échantillons appariés
Type:
Test d'hypothèse paramétrique de type intervalle de confiance souvent utilisé unilatéral.
Concerne:
La différence de deux moyennes de deux échantillons identiques
Contrainte(s):
Distribution Normale des données
(7) Test-Z
Type:
Test d'hypothèse paramétrique de type intervalle de confiance plus utilisé en bilatéral qu'en unilatéral.
Concerne:
La moyenne lorsque l'écart-type théorique est connu
Contrainte(s):
Distribution Normale des données

8) Test-Z de la moyenne à deux échantillons
Type:
Test d'hypothèse paramétrique de type intervalle de confiance souvent utilisé en bilatéral
Concerne:
La différence de deux moyennes lorsque les écarts-types théoriques sont connus
Contrainte(s):
Distribution Normale des données
(9) Test du Khi-deux
Type:
Test d'hypothèse paramétrique de type intervalle de confiance souvent utilisé en bilatéral
Concerne:
La variance théorique
Contrainte(s):
Distribution Normale des données
(10) Test-F de Fisher
Type:
Test d'hypothèse paramétrique de type intervalle de confiance souvent utilisé en bilatéral
Concerne:
La comparaison de deux variances théoriques
Contrainte(s):
Distribution Normale des données
(11) Test-T homoscédastique
Type:
Test d'hypothèse paramétrique de type intervalle de confiance souvent utilisé en unilatéral
Concerne:
L'égalité de deux moyennes
Contrainte(s):
Distribution Normale des données et égalité des variances expérimentales

(12) Test-T hétéroscédastique
Type:
Test d'hypothèse paramétrique de type intervalle de confiance souvent utilisé en unilatéral
Concerne:
L'égalité de deux moyennes
Contrainte(s):
Distribution Normale des données et non-égalité des variances expérimentales (cas généralisé du Test-T
homoscédastique)
(13) Test de l'ANOVA à un facteur contrôlé
Type:
Test d'hypothèse paramétrique de type intervalle de confiance utilisé uniquement en unilatéral
Concerne:
L'égalité des moyennes des échantillons (supposés implicitement appariés)
Contrainte(s):
Distribution Normale des données avec variances théoriques identiques et variances expérimentales connues et
indépendance des échantillons. Les résidus doivent in extenso aussi être normalement distributés
(14) Test de l'ANOVA à deux facteurs contrôles avec ou sans répétition
Type:
Test d'hypothèse paramétrique de type intervalle de confiance utilisé uniquement en unilatéral
Concerne:
L'égalité des moyennes des échantillons fonction d'un paramètre variable contrôlable (ajustable).
Contrainte(s):
Distribution Normale des données avec variances théoriques identiques et variances expérimentales connues et
indépendance des échantillons. Les résidus doivent in extenso aussi être normalement distributés.
(15) Test d'ajustement (dit aussi "test d'adéquation de Pearson") du Khi-deux
Type:
Test d'ajustement paramétrique utilisé uniquement en unilatéral
Concerne:
Adéquation de valeurs expérimentales à une loi théorique
Contrainte(s):
Avoir suffisamment de classes d'intervalles et de données
Remarque: Appelé "Test de normalité" si comparé à une loi Normale.

(16) Test d'indépendance du Khi-deux
Type:
Test d'ajustement (étudié dans le chapitre de Méthodes Numériques) paramétrique utilisé uniquement en
unilatéral
Concerne:
Vérifier la dépendance ou l'indépendance (différence) de données provenant d'une table de contingence. Vérifie
donc si les moyennes sont différentes ou pas entre groupes en se basant sur la contingence
Contrainte(s):
Avoir suffisamment de classes d'intervalles et de données
(17) Test de la médiane
Type:
Test d'hypothèse non paramétrique étudié dans le chapitre de Méthodes Numériques de type intervalle de
confiance toujours utilisé en bilatéral
Concerne:
La médiane
Contrainte(s):
Un nombre d'échantillons suffisant pour faire un bootstrap.

(19) Test de Poisson à un et deux échantillons
Type:
Tests d'hypothèses paramétrique tantôt en unilatéral ou bilatéral basé sur les événements rares (dixit la moyenne
de la loi de Poisson)
Concerne:
Déterminer un intervalle de confiance pour l'occurrence d'événements rares sur une période donnée afin
d'identifier une anomalie ou une différence significative par rapport à des objectifs ou des nromes.
Contrainte(s):
Les événements suivent une loi de Poisson mais sont approximés dans le cas à deux échantillons par une loi
Normale...

(24) Test exact de Fisher
Type:
Test d'ajustement (étudié dans le chapitre de Méthodes Numériques) paramétrique utilisé principalement en
bilatérial
Concerne:
Vérifier si la configuration observée dans un tableau de contingence est une situation extrême par rapport aux
situations possibles.
Contrainte(s):
Aucune en particulière

Les tests non paramétriques (comme les deux tests du Khi-deux déjà vus) ne font eux aucune
hypothèse sur la distribution sous-jacente des données. L'étape préalable qui consistait uniquement à
estimer les paramètres des distributions avant de procéder au test d'hypothèse proprement dit n'est plus
nécessaire.
Lorsque les données sont quantitatives, les tests non paramétriques transforment les valeurs en rangs.
L'appellation "tests de rangs" est alors souvent rencontrée. Lorsque les données sont qualitatives, seuls
les tests non paramétriques sont utilisables.

========== RANG

on ordonne toutes les valeurs de X et Y
la première est R1 (rang 1), si deux valeurs == alors même i-ème de rang

On fait la somme des i pour chaque X/Y : Valeurs que nous appelons "statistique de Wilcoxon".

l'espérance de la loi discrète uniforme
(n+1)/2 = mu
n^2-1/12 = V(x)

---------- TEST DE LA SOMME DES RANGS DE MANN-WITHNEY

Le "test de la somme des rangs de Mann-Withney" est au fait un test d'ajustement non-paramétrique
très simple qui se déduit du test de la somme des rangs de Wilcoxon. Par ailleurs il en est inspiré à un
tel point que nous l'appelons parfois dans l'industrie le "test de Wilcoxon-Mann-Withney" ou "test
d'ajustement de Wilcoxon-Mann-Withney" ou encore"test MWW" (sans spécifier à chaque fois qu'il
repose sur la somme des rangs).

Le but de ce test, identiquement au test de la somme des rangs de Wilcoxon, est de trouver un moyen
de vérifier que deux échantillons indépendants non nécessairement de même taille sont issus d'une
même loi ou non (in extenso sont issus d'une même population ou non) mais avec une approche
différente!

---------- TEST DE LA SOMME DES RANGS SIGNÉS DE WILCOXON À 1 ÉCHANTILLON

Le but du test de la "somme des rangs signés de Wilcoxon", appelé aussi parfois "test de la médiane de
Wilcoxon", est d'utiliser une technique non paramétrique pour vérifier la symétrie ou non d'une
distribution et donc in extenso faire une hypothèse sur la valeur de la médiane. L'idée est à la fois
simple et subtile.

Le principe et que si nous comparons les différences des individus d'un échantillon par rapport à la
médiane, nous savons que si nous avons (par exemple) un nombre impair d'individus tous différents
(non égaux), alors nous aurons 50% des données au-dessus et en-dessous de la médiane. Ensuite, pour
contrôler que la distribution des valeurs des individus vérifie une certaine symétrie, l'idée (simple mais
astucieuse) consiste ensuite à:
1. Calculer les différences en valeur absolue par rapport à la médiane
2. Ranger ces différences absolues par ordre croissant et leur assigner leur rang respectif
3. Calculer la somme des rangs des différences qui à la base sont négatives
4. Calculer la somme des rangs des différences qui à la base sont positives
et si l'échantillon a une distribution symétrique (donc la médiane est confondue alors avec la moyenne),
il devrait y avoir une somme des rangs négatifs qui n'est pas significativement différente de la
sommes des rangs positifs .

------- TEST DE LA SOMME DES RANGS SIGNÉS DE WILCOXON POUR 2 ÉCHANTILLONS APPARIÉS
Le "test de la somme des rangs signés de Wilcoxon pour 2 échantillons appariés" est basé à 100% sur le
principe du test à 1 échantillon. La seule différence est que l'hypothèse nulle ou alternative est basée
sur la différence de la médiane des données prises deux à deux de chacun des échantillons. Dans la
majorité des cas, l'hypothèse nulle est que la médiane des différences est nulle contre l'hypothèse
alternative qu'elle est significativement différente de zéro.

-------- TEST DE KRUSKAL-WALLIS

Le test de Kruskal-Wallis un test non paramétrique souvent assimilé (un peu rapidement...) à une
ANOVA non paramétrique à une voie pour comparer si deux populations ou plus ont même médiane
(hypothèse nulle) à la différence qu'il ne nécessite donc pas les hypothèses nécessaires au
fonctionnement de l'ANOVA. Quand plusieurs populations comparées passent à travers ce test, ce
dernier ne dit pas quelle population est significativement différente mais uniquement qu'il y en a au
moins une qui l'est. En réalité, comme nous allons le démontrer, le test de Kruskal-Wallis n'est qu'une
extension du test U de Mann-Whitney vu plus haut pour un nombre de populations supérieur ou égal à
trois.