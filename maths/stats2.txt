structure
-----------------

Sous-partie d'un dataframe, subset(stid,Sexe==2,select=c(Groupe,Sexe,Note.Fr.))
-> select : variables gardées, -> stid : fichier, -> sexe==2 : condition

library(lattice)	regroup<-make.groups(nom=valeur, ...)

order(vecteur) : donne les indexes dans l'ordre

esprit d'analyse
----------------------

Skewness et Kurtosis
	Lorsque le skewness est proche de 0, la distribution est symétrique.
	Kurtosis est un coefficient mesurant l'aplatissement si
	Kurtosis alors la répartition est équilibrée, si Kurtosis est important
	alors il y a un pic à un endroit. Une loi gaussienne corresponds à Kurtosis=3.

??? Ajustement linéaire
	Coefficient de corrélation (cor) et une droite de régression (lm)
	coefficients(modele)
	Le coefficient de corrélation linéaire est assez élevé (un test le prouverait).
	Le nuage a une forme allongée, on peut donc effectuer un ajustement linéaire.
	Il est possible de récupérer les valeurs des résidus (residuals(modele)) et les valeurs
	y prédites (fitted(modele)).

	Matrices de graphiques (pairs, GGally)
		Étudier la liaison entre plusieurs variables numériques

	Matrice des corrélations
		Repérer les liens entre les variables quantitatives.

		Les coefficients de corrélation linéaire sont calculés et représentés sous forme de carrés
		de couleurs Pour cela, nous avons besoin d’une extension corrplot.

		library(corrplot); corrplot(M, method="circle")

		Cela affiche une cercle avec 1 : ... et -1 ...

Statistique inférentielle (tests)
=====================================

Tests d'égalités de variances : ~ Indépendance requise.

3. Test T pour données appariées (Paired)
Lorsque les échantillons ne sont pas indépendants, le test précédent n’est plus applicable.

Un plan B a été inventé dans le cas où les 2 échantillons n’en sont qu’un seul : par exemple
lorsque des mêmes individus ont été mesurés deux fois. Dans ce cas, nous calculons la différence
pour chaque individu (cohérent car ce sont les mêmes) et nous testons la nullité.

Test de nullité du coefficient de corrélation linéaire
	Ce test permet de vérifier la liaison entre deux variables quantitatives (gaussiennes ou plus
	de 30 effectifs)

	cor et cor.test

	Nous savons que r doit être compris entre -1 et 1 et que, lorsque le coefficient est proche de 1 ou de -1, cela
  peut être le signe d’une corrélation linéaire. Dans la pratique, il est préférable d’utiliser un test pour savoir si
  ce coefficient est significativement non nul.

Matrice des corrélations
 Si vous avez besoin de calculer les corrélations 2 à 2 entre n variables quantitatives,
 il existe un bon outil : la matrice des corrélations.

	voir plus avant

	# Pour avoir le test de significativité
	cor.mtest
	Les valeurs en dessous de 5% = corrélation

	M<-cor(froment[,2:6])
	corrplot(M, method="circle")
	corrplot(M, method="number") // avec des nombres
	corrplot(M, method="number", type='upper') // partie sup

http://www.sthda.com/french/wiki/visualiser-une-matrice-de-correlation-par-un-correlogramme

Liaison entre une variable qualitative
et une quantitative : Analyse de la variance (Anova)
	Nous avons vu dans les paragraphes précédents comment comparer 2 moyennes.
	 La méthode présentée ici généralise cela.

	 ----> Anova à un critère

	 Elle a pour but de mesurer la liaison entre une variable qualitative (le type d’arbre) et une variable
   quantitative (la hauteur). Cela revient à comparer les moyennes de k populations qui son supposées
   normales27et de même variance28, à partir d'échantillons aléatoires et indépendantsles uns des autres.

   Ce nombre, compris entre 0
   et 1 mesure l'intensité de la liaison entre X et Y. S'il vaut zéro il n'y a aucune liaison entre X et Y. Inversement,
   s'il vaut 1, la liaison est parfaite.

   Si F est supérieur à la valeur critique (ou si p est inférieur à la valeur de référence (0.05 en général)), on
   rejette H0. Les moyennes entre différentes classes sont significativement différentes, la variable X a donc une
   influence sur Y ou encore, le pouvoir discriminant de X sur Y est significatif.

   analyse <- aov(Hauteurs ~ Types, data=arbres)# analyse de variance
   summary(analyse)
   La pvaleur est inférieure à 5% (0,00261), nous rejetons donc H0.
   Il y a donc une différence significative entre les moyennes.
   (Type d'arbre dépends de la forêt)

   Tests de Tukey
   Ces tests permettent de savoir quelles sont les moyennes qui différent des autres.
   TukeyHSD(analyse)
   diff de -2 donc  différence significative
   p adj en dessous de 5% aussi
   tapply(arbres$Hauteurs,arbres$Types,shapiro.test)

	 ----> Anova à deux critères
   Lorsque nous voulons étudier l’influence de deux variables qualitatives sur une variable
   quantitative, il est possible de faire deux ANOVA à un critère mais nous perdons alors
   la possibilité de voir une interaction entre les deux facteurs.

Stop page 260/451