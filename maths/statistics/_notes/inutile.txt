Cartographie simple avec R, Carte choroplèthe
->R possède la capacité de représenter des données géographiques grâce à ggplot.
->library(ggplot2) library(dplyr) require(maps) require(viridis)
->world_map <- map_data("france")
->left_join(donnees, france_map, by = "region")

attach(Donnees) ???
interaction.plot(Sol, Sonde, Teneur,lwd=2,ylab="Teneur moyenne", main="Effet du facteur Sol en fonction du facteur Sonde")
Représentation des interactions
3 droites, une par sonde en fonction du sol (x) par la teneur (y)
Nous voyons que les trois droites sont quasiment parallèles. L’effet du facteur Sol (pente d’une droite) ne dépend pas de la sonde choisie (les trois pentes sont quasiment les mêmes).
Il n’y a donc pas d’interaction Sol Sonde sur Teneur.

============================= MOAR

L'analyse de données en masse la "statistique fréquentielle" (en opposition à l'inférence bayésienne).

Médiane : M = a + (b-a) * \frac{0.5-F(a)}{F(b)-F(a)}

La "moyenne quadratique" parfois simplement notée Q qui est définie par: ...
racine m-ième de la somme des xi^m/n. L'écart type est une moyenne quadratique.

P3. La somme pondérée des écarts à la moyenne arithmétique est nulle.

la "fonction de survie" (survival function) ou "fonction de queue" : 1-F(x)

Diversité (ex: vendeurs/produits et le taux de divsersité)
Formule de Shannon
N = nombre de produits
N log(N) - (freq_prod_i * log(freq_prod_i))
/
N

============================ UNKNOWN

Souvent en statistique, il est utile de déterminer l'écart-type de la moyenne empirique (ou en d'autres
termes...: l'erreur quadratique moyenne). Voyons de quoi il s'agit:

en gros si sont identiquement distribuées et indépendantes
alors E(X) = 1/n * n mu
sinon  1/n * somme des espérances

variance : 1/n^2
V(x) = sigma^2/n
--> d'où l'écart-type de la moyenne appelé aussi "erreur-type", "erreur-standard" ou encore "variation non systématique":
sigma(x) = sigma/sqrt(n)

la loi de probabilité de la
variable aléatoire X, moyenne de n variables aléatoires identiquement distribuées et linéairement
indépendantes, est alors la loi:
N(mu, sigma/sqrt(n))

---> ESTIMATEURS DE LA LOI GAMMA

Nous allons utiliser ici une technique appelée "méthode des moments" pour déterminer les estimateurs
des paramètres de la loi Gamma.
Supposons que X1, ..., Xn sont des variables aléatoires indépendantes et identiquement distribuées selon
la loi Gamma avec pour densité:

Le premier moment est l'espérance (a/lambda)
Le second moment est la variance (a(a+1)/lambda^2)

Une fois ce système établie, la méthode des moments consiste à utiliser les moments empiriques, en
l'occurrence pour notre exemple les deux premiers
que l'on pose égaux aux moments théoriques vrais...

---------------> coefficient de détermination

L'analyse du coefficient de corrélation poursuit donc l'objectif de déterminer le degré d'association
entre les différentes variables: celui-ci est souvent exprimé par le coefficient de détermination,
qui est le carré du coefficient de corrélation. Le coefficient de détermination mesure donc
la contribution d'une des variables à l'explication de la seconde.

---------------> facteur de correction sur population finie

Maintenant démontrons un autre résultat qui nous sera indispensables dans certains tests statistiques
que nous verrons plus loin.

fcp
fpc = "facteur de correction de population" ou
      en anglais "finite population correction factor"
      = (n-k)/(n-1)

que nous avons déjà rencontré lors de notre étude la loi hypergéométrique, et appelé "facteur de
correction sur population finie" et il a pour effet de réduire l'erreur-standard d'autant plus que n est
grand.

(multiplie par fcp)

-------------->

R1. Le terme est souvent indiqué dans l'industrie par l'abréviation SST signifiant en anglais
"Sum of Squares Total" ou plus rarement TSS pour "Total Sum of Squares".
R2. Le terme est souvent indiqué dans l'industrie par l'abréviation SSB signifiant en anglais
"Sum of Squares Between (samples)" ou plus rarement SSk pour "Sum of Squares Between
treatments".
R3. Le terme est souvent indiqué dans l'industrie par l'abréviation SSW signifiant en anglais
"Sum of Squares Within (samples)" ou plus rarement SSE pour "Sum of Squares due to Errors".

------------> RANG

on ordonne toutes les valeurs de X et Y
la première est R1 (rang 1), si deux valeurs == alors même i-ème de rang

On fait la somme des i pour chaque X/Y : Valeurs que nous appelons "statistique de Wilcoxon".

l'espérance de la loi discrète uniforme
(n+1)/2 = mu
n^2-1/12 = V(x)