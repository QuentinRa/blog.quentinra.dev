Les tests paramétriques: ces tests portent sur la valeur d'un ou de plusieurs paramètres
de la distribution dans la population d' une variable d' intérêt.
2. Les tests non-paramétriques : ces tests portent sur la distribution, les moments
(espérance, variance, etc.) ou certaines caractéristiques (l'indépendance par
exemple) d' une ou de plusieurs variables aléatoires.

====================
Regression linéaire
====================

6. Gérer la corrélation
==========================

Pour avoir un modèle qui se casse pas trop la figure, il faut essayer d'avoir un minimum de
corrélation entre les variables explicatives. Calculez la corrélation ou
la matrice de corrélations et regardez. S'il y a des corrélations évidentes,
alors il va valoir faire des choix.

La fonction :code:`rs <- regsubsets(...,nbest=n)` du package :code:`leaps`
avec ... les arguments de votre lm. Il va nous montrer
les meilleurs combinaisons possibles de vos variables.

regsubsets va chercher les meilleurs combinaisons avec 1 variables, 2, ...
nbest détermine le nombre de combinaisons qu'il vous montre

	* nbest = 2 et on a X1 X2 X3
	* X1 (1/2)
	* X2 (2/2)
	* X1 X2 (1/2)
	* X1 X3 (2/2)
	* ... pourrait être un résultat possible)

Il faudra choisir un modèle avec une faible RSE et un fort :math:`R^2`.

Vous aimez pas les étoiles ? Pas de problèmes, tracez
votre truc :code:`plot(rs,scale="adjr2", main="Modèles classés en fonction de r² ajusté")`
et les carrés blancs indiquent que pour obtenir un taux entre de :math:`R^2` entre
les deux y du carrés alors vous devez prendre cette valeur X.

.. image:: /assets/math/stats/subset.png

Vous n'aimez toujours pas ? Dernière alternative avec la librairie :code:`car`
et sa fonction :code:`subsets(rs, statistic="adjr2", legend = "topleft")`. On cherche
les plus petites valeurs.

7. Autres
===========

Si vous souhaitez faire des prédictions, cela se fait avec :code:`predict(model, V, interval="predict",level=0.95)`
avec V qui est un vecteur correspondant aux valeurs que vous avez prévues pour vos
VA. Il existe une forme sans V.

Ce n'est pas abordé mais la distance de Cook mesure l’influence
de l’observation sur les coefficients de régression avec

.. code:: R

		library(olsrr)
		ols_cooksd_chart(model)

vous utilisez la même loi théorique proposée
(donc Gaussienne par exmeple au problème 11)
ce qui change est le paramètre
pour le paramètre vous utilisez l'estimateur de MV obtenu
et puis vous faites vos simulations de bootstrap paramétrique en faisant des échantillons de même loi suivant thetaMV
Vous allez donc obtenir une echantillon iid d'estimateurs, à partir de laquelle vous pouvez construire un intervalle de confiance

Vous allez obtenir un echantillon de parametrez
par example, si vous utilisez M = 1000, vous allez avoir 1000 estimateurs différentes
Que vous regardez comme des réalisation iid d'une même variable aléatoire
Appelons Y cette variable aléatoire pour l'instante
Vous cherchez donc des valeurs a et b telles que P( a <= Y <= b ) >= 0.95
alors, la proposition est de prendre a = quantile 0.025 de la loi empirique
b= quantile 0.975 de la loi empirique

lorsque vous optimisez une fonction f(x), avec x appartenant à un domain D, le maximum se trouve toujours soit aux points f'(x)=0, soit aux limites du domaine