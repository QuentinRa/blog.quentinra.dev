# Data governance

<div class="row row-cols-md-2"><div>

We define 

* roles 
* responsibilities
* practices
</div><div>

#### The DIKW model

The DIKW model <small>(Data, Information, Knowledge, Wisdom)</small> is a pyramid-shaped model that represent how "data" is transformed to "wisdom". The goal is to show understand how raw data can be transformed in useful information.

Raw data <small>(ex: 1984)</small> is transformed to information by adding a context <small>(ex: Los Angeles summer olympics)</small>. By interpreting the information, it becomes knowledge <small>(ex: it occurs every 4 years)</small>. And trough reflexion, it become wisdom <small>(ex: the next one will be in 2024)</small>.
</div></div>

* **Lack of quality**: cost to fix it. A data is meaningful/qualitative if it fits its purpose, so it does not have to be perfect as long as you can use it for your needs.

<hr class="sep-both">

## Data Management Association (DAMA) framework

<div class="row row-cols-md-2"><div>

The Data Management Association (DAMA) framework is an approach to data governance.

➡️ See DAMA wheel on Google/... Here is a text summary:

1. **Data Modeling and design**: what is the data and why do we need it? What are the regulations/...?
2. **Data Storage & Operations**: where will we store the data?
3. **Data Security**: processes set to prevent unauthorized access, data misuse...
4. **Data integration & Interoperability**: how is the data shared/passed between each service?
</div><div>

5. **Documents & Content Management**: how and where are physical documents stored?
6. **Reference & Master Data**: classification of data in groups according to some criteria <small>(ex: sensitive data...)</small>
7. **Data Warehousing & Business Intelligence**: software/systems to help the higher-ups understand what kind of clients they have/... to manage the company.
8. **Metadata**: describe what kind of data we have
9. **Data Quality**: techniques used to ensure data accuracy, completeness, and consistency.
10. **Data Architecture**: the overall design and structure of the data and information systems within an organization
</div></div>

<hr class="sep-both">

## Data classification and valuation

<div class="row row-cols-md-2"><div>

#### Classification

At the top, the semantic is the most important as it will impact the quality of the element below. Problems at the top will impact a lot the business. The more we go down, the more we have data.

* **Metadata**: describe what kind of data we have
* **Reference data**: data used as a reference for other data, such as a list of countries, ranks for customers <small>(iron, gold, diamond)</small>...
* **Structural data**: External entities <small>(ex: providers, clients...)</small> and the data related to the service/product <small>(ex: delivering address...)</small>
* **Organizational data**: data about the company <small>(ex: employees, sales inventory, departments, hierarchies...)</small>
* **Operational data**: data generated by the activity of the company <small>(ex: orders, invoices...)</small>
* **Audit data**: logs of every change of the data

➡️ We call "Master data" the structural, organizational, and operational data altogether. This is the core and critical data of the company which is considered the single source of truth.
</div><div>

#### Valuation

It's important to associate a value to data in order to find which data require more resources <small>(ex: more advanced measures for VIP...)</small>...

* How much did it cost to acquire this data?
* How much will it cost if we damaged/lost this data?
* What's the impact if this data isn't available?
* The value it adds to business operations/decision-making.
* The revenue generated using this data.
* The cost to protect this data <small>(+in accordance to regulations)</small>
* How much would the competitors pay for this data?
* The date of acquisition? <small>(newer data are more valuable)</small>
* ...

#### Critical data

It's important for a company to understand what are their critical data, so that they can focus their resources on it. Assessing if a data is critical could be do using 

* a risk assessment process based on its value
* a role-based risk assessment evaluate the risk for each role by each data inside the company

<details class="details-n">
<summary>Role-based risk assessment as table</summary>

**Rows**: we would have a group of rows called "client" in which sub-rows would be the properties such as it's name, address...

**Columns**: we could have column which are services <small>(ex: marketing, sales...)</small>, which are sub-divided into roles within a service <small>(ex: marketing campaign, order management...)</small>.

**Values**: the values are an access level <small>(R=Read, U=Update, or C=Create)</small> and a risk level <small>(1=Not critical to 5=Critical)</small>.

For instance, the ones creating orders in the sales department need a client's address, so we would have C5 in the row "Client > address" and the column "Sales > orders".
</details>
</div></div>

<hr class="sep-both">

## Metadata

<div class="row row-cols-md-2"><div>

At some point, you will have to define metadata. They describe

* the data
* the concept the data represent <small>(ex: a Person, an Address...)</small>.
* the relation between data and concepts
* how the data is used, stored, and retained
* the transformations <small>(ex: derived attributes in SQL)</small>
* the validations/quality checks <small>(ex: constraints in SQL)</small>
* how much is the data important/needed for the company
* who is the owner <small>(usually, it's the company)</small>
* what's the origin of the data
* who can access this data, and what they can do with it

➡️ It must be clear where are Metadata stored and what's inside.

#### Models

Models are used to explain in a standardized way something. According to the target, the model will have more or less details

* conceptual models: high-level concepts
* logical models: relationship between data elements
* physical models: how the data is stored <small>(ex: UML diagrams)</small>
</div><div>

#### Glossary of terms

A glossary of terms is used to describe every term <small>(ex: Client)</small>

* A description of what the term is, descriptive, unambiguous, with hyperlink to other terms <small>(see ISO-11179)</small>
* Add abbreviations, acronyms, synonyms, translations...
* Add any relation between terms
* Add management information <small>(When was this term added? By who? Who approved it? ...)</small>

It's a good practice to use a taxonomy to categorize business terms in a structured way. A taxonomy is usually made of terms which are either Governance terms <small>(added to facilitate the management of the glossary)</small>, and semantic terms <small>(business-related)</small>. A semantic term is usually either about

* Entities <small>(things, activities, actors)</small> within the business domain, and that the business deals with
* Properties <small>(identifiers, attributes, conditions)</small> owned by entities
</div></div>

<hr class="sep-both">

## Data life-cycle

<div class="row row-cols-md-2"><div>

Note that the life-cycle of the data may change according to what kind of data is handled.

1. **Planning**: what information do we need? For what purpose?

➡️ Take into account laws, directives, requirement, risks...

2. **Design and Implementation**: define how and where the data will be structured, stored, along the relationship between data

➡️ Define standards, policies, use cases, responsibilities, tests, audits... The modeling team must be made aware of security constraints.

3. **Creation/Acquisition**: collecting, importing, validating data...

➡️ At some point, data will be destroyed after this step.

4. **Storage and Maintenance**: store the data in a secure maintainable and accessible place. Backups may be performed at this step too.

➡️ Define a retention policy, a business continuity plan...

5. **Usage**: to provide the service, in decision-making...
6. **Enhancement**: updating, adding new information, refining the data... to make it more relevant to the business needs.

#### Data Retention Policy

Each data should have a retention rule describing how long they are retained, where <small>(location, based on classification?, chronologically?)</small>, how <small>(format, media)</small>, and who will archive/manage it, ensure it's destroyed... The choice is mainly based on legal requirements.

#### Data Destruction

Ensuring a file is removed is hard because even after clearing the recycle bin, the file still exists but is marked as free space. We could defragment the disk or destroy it <small>(costly, we could have to do a process more advanced based on the classification...)</small>.

This is the same in a database, in relational database, we should compress/defragment the file.

</div><div>

#### Data quality

During the creating, storage, and usage, we need to ensure that the data created/stored/used if of high quality.

1. **Accurate**: represent the truth (in real life)
2. **Complete**: every entity and required properties are present
3. **Consistent**: uniform between datasources
4. **Referential integrity**: elements are correctly linked
5. **Up-to-date**: promptly updated
6. **Unique**: no duplicates
7. **Valid**: within the expected range...
8. **Relevant**: useful for the organization
9. **Trustworthy**: the source is known
10. **Available**: those who need it can access it
11. **Protected**: only those allowed can access it
12. **Understandable**: the definition is both shared and clear

To improve the data quality, we could profile data to find outliers/extremums, ask the ones using the data... It's important to find the cause of low quality data. Note that when handling problems, you need to prioritize data based on their critical value. Also, there may be existing quality rules based on industry standards, regulatory requirements, and business needs.

➡️ See "Plan - Correct - Monitor - React".
</div></div>

<hr class="sep-both">

## Data management

<div class="row row-cols-md-2"><div>

#### Principles/Policies/Guidelines/Standards

The PPGS are defining the rules and standards for data management.

* Principles: high-level guidance <small>(why do we need this data?)</small>
* Policies: more specific rules <small>(what do we need?)</small>
* Guidelines: recommendations and best practices <small>(how?)</small>
* Standards: technical specifications <small>(quality...)</small>

#### Gartner's GAIP

Gartner released a research report provides guidelines for improving data management called "Generally Accepted Information Principles for Improved Information Asset Management".

#### The five "As" in data management

The 5 "As" is a framework to describe the five key aspects of effective data management:

1. Availability
2. Accuracy
3. Accessibility
4. Appropriateness
5. Auditability
</div><div>

#### Levels of data management

To start with data governance, you could follow these steps

* Find someone who want to improve the data quality
* Find what is the problem or element needing improvement
* Find what are the causes
* Redact a plan to fix the problem
* Display the positive impact of fixing the problem

Finally, you can formalize the data governance. There are five levels of data management:

1. Ad hoc: individuals manage data in their own way
2. Repeatable: departments establish basic policies/procedures
3. Defined: the organization start formalizing data management
4. Managed: data is actively monitored and inventoried
5. Optimized: data management is implicit in all business processes, and continuously improved

The goal is to move from the lower levels to the higher levels, where data is managed effectively and driving business value.
</div></div>

<hr class="sep-both">

## Security and access control

<div class="row row-cols-md-2"><div>

#### CIA for data security

If we apply the security triad (CIA):

* Confidentiality: only those allowed can access data
* Integrity: data was not tampered with
* Availability: data is available when needed <small>(backups...)</small>

For security practices to be useful, everyone, regardless of their task, must be aware of what it takes to protect data. Everyone should know who to contact if they detect a problem.

#### The five "As" in security

The 5 "As" is a framework to describe key aspects of security:

1. Authentication: verify a user/device before granting access
2. Authorization: determine what the user can do
3. Access: allow the user to retrieve/edit information
4. Admissibility: everything that the user has access to
5. Audit: monitor access to ensure their appropriate use

</div><div>

#### Data Access control

Each organization much define some levels of access control with clear rules defining in which category every data is in. Ex:

* **Public**: information that won't harm the company
* **Sensitive**: information that should be closely monitored but won't harm much the company if disclosed <small>(ex: next free games)</small>
* **Private**: information that will impact users or the company if disclosed <small>(ex: browser history)</small>
* **Confidential**: information that will harm users or the company if disclosed <small>(ex: credit card data)</small>

A company must define the controls applied to each level, and communicate to every one clearly which information is classified in which level of classification. It's usually based on the value, the whether the data is sensitive or critical.

➡️ Using inference, someone can use non-confidential data such as birthdate, postal code, and gender to find someone.

#### Data breaches

* The company must find, and patch the vulnerability
* The company must inform the clients
* The company will have to pay fines
* The company will lose reputation

To prevent data breaches, the company after identifying, classifying, and prioritizing data, should find why data is likely to be targeted along the risks, and define required protections.
</div></div>